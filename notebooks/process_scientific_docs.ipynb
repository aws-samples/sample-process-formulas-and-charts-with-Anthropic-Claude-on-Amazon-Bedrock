{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Documents Containing Scientific Formulas and Charts using Anthropic Claude on Amazon Bedrock\n",
    "---\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>NOTE:</b> You will need to use a Jupyter Kernel with Python 3.11 or above to use this notebook. If you are using an Amazon Sagemaker Notebook Instance use conda_python3. If you are using SageMaker Studio, you can use the `Data Science 3.0` image.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    <b>NOTE:</b> You will need 3rd party model access to Anthropic Claude Sonnet 3.5 V2 model to be able to run this notebook. Verify if you have access to the model by going to <a href=\"https://console.aws.amazon.com/bedrock\" target=\"_blank\">Amazon Bedrock console</a> > left menu \"Model access\". The \"Access status\" for Anthropic Claude must be in \"Access granted\" status in green. If you do not have access, then click \"Edit\" button on the top right > select the model checkbox > click \"Save changes\" button at the bottom. You should have access to the model within a few moments.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "Prerequisites and Environment Setup\n",
    "1. Data Preparation\n",
    "1. Formula Extraction\n",
    "1. Chart and Graph Analysis\n",
    "1. Metadata Generation\n",
    "1. Comprehensive Document Processing \n",
    "1. Knowledge Base Integration\n",
    "1. Query Capabilities\n",
    "1. Cleanup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites and Environment Setup\n",
    "---\n",
    "This section sets up the required environment and dependencies for processing scientific documents. It includes installing essential packages like poppler for PDF processing and defining helper functions for interacting with Amazon Bedrock. The setup is crucial for enabling the document processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda install -c conda-forge poppler -y\n",
    "!python -m pip install sagemaker\n",
    "!python -m pip install filetype\n",
    "!python -m pip install pdf2image\n",
    "!python -m pip install retrying\n",
    "!python -m pip install opensearch-py\n",
    "!python -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import requests\n",
    "import os\n",
    "import boto3\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex, Image\n",
    "import filetype\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image import pdfinfo_from_path\n",
    "from pathlib import Path\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "session = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "foundation_model = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "\n",
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Get current accountid\n",
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "knowledge_base_name_hierarchical = 'hierarchical-kb'\n",
    "knowledge_base_bucket_name = os.getenv(\"BUCKET_NAME\", f\"{account_id}-bedrock-kb-{suffix}\")\n",
    "knowledge_base_description = \"Knowledge Base containing research PDF.\"\n",
    "\n",
    "\n",
    "print(f\"SageMaker Execution Role is {role}. Current region is {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_type(file_path):\n",
    "    file_types = {\n",
    "        'application/pdf': 'pdf',\n",
    "        'image/jpeg': 'jpeg',\n",
    "        'image/png': 'png',\n",
    "        'image/webp': 'webp',\n",
    "        'text/plain': 'txt',\n",
    "        'text/csv': 'csv'\n",
    "    }\n",
    "\n",
    "    file_type = None\n",
    "    kind = filetype.guess(file_path)\n",
    "    if kind and kind.mime in file_types:\n",
    "        file_type = file_types[kind.mime]\n",
    "    \n",
    "    return file_type\n",
    "\n",
    "messages = []\n",
    "def stream_conversation(message, modelId=foundation_model, file_paths=[], temp=0.2):\n",
    "    \"\"\"\n",
    "    Sends messages to a model and streams back the response.\n",
    "    Args:\n",
    "        message: The text message to send to the model.\n",
    "        modelId: The ID of the model to use for the conversation.\n",
    "        file_paths: A list of file paths to include in the conversation.\n",
    "        temp: The temperature for the model inference.\n",
    "        \n",
    "    Returns:\n",
    "        A generator that yields the streaming response.\n",
    "    \"\"\"\n",
    "    temperature = temp\n",
    "    top_k = 200\n",
    "    inference_config = {\"temperature\": temperature}\n",
    "    additional_model_fields = {\"top_k\": top_k}\n",
    "    model_id = modelId\n",
    "\n",
    "    system_prompts = [{\"text\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "    content = []\n",
    "    file_types = {\n",
    "        'application/pdf': 'pdf',\n",
    "        'image/jpeg': 'jpeg',\n",
    "        'image/png': 'png',\n",
    "        'image/webp': 'webp',\n",
    "        'text/plain': 'txt',\n",
    "        'text/csv': 'csv'\n",
    "    }\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if file_path:\n",
    "            with open(file_path, \"rb\") as open_file:\n",
    "                file_bytes = open_file.read()\n",
    "            \n",
    "            # get the filename\n",
    "            file_name = os.path.basename(file_path)\n",
    "\n",
    "            #clean filename to remove any non alphanumeric characters\n",
    "            file_name = ''.join(e for e in file_name if e.isalnum())\n",
    "\n",
    "            file_type = get_file_type(file_path)\n",
    "            if file_type is not None:\n",
    "\n",
    "                if file_type in \"png jpeg gif webp\":\n",
    "                    content.append({\"image\": {\"format\": file_type, \"source\": {\"bytes\": file_bytes}}})\n",
    "                elif file_type == \"pdf\":\n",
    "                    content.append({\"document\": {\"format\": file_type, \"name\": file_name, \"source\": {\"bytes\": file_bytes}}})\n",
    "\n",
    "    content.append({\"text\": message})\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content,\n",
    "    }\n",
    "    message_list = [message]\n",
    "\n",
    "    response = bedrock.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=message_list,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "    stream = response.get('stream')\n",
    "    \n",
    "    output = \"inspecting stream ...\\n\"\n",
    "    message = {}\n",
    "    if stream:\n",
    "        streaming_text = \"\"\n",
    "        \n",
    "        for event in stream:\n",
    "            if 'messageStart' in event:\n",
    "                output += f\"\\nRole: {event['messageStart']['role']}\"\n",
    "\n",
    "            if 'contentBlockDelta' in event:\n",
    "                #yield event['contentBlockDelta']['delta']['text']\n",
    "                streaming_text += event['contentBlockDelta']['delta']['text']\n",
    "\n",
    "            if 'messageStop' in event:\n",
    "                output += f\"\\nStop reason: {event['messageStop']['stopReason']}\"\n",
    "                \n",
    "                message = {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": streaming_text\n",
    "                }\n",
    "\n",
    "            if 'metadata' in event:\n",
    "                metadata = event['metadata']\n",
    "                if 'usage' in metadata:\n",
    "                    output += \"\\nToken usage\"\n",
    "                    output += f\"Input tokens: {metadata['usage']['inputTokens']}\"\n",
    "                    output += f\":Output tokens: {metadata['usage']['outputTokens']}\"\n",
    "                    output += f\":Total tokens: {metadata['usage']['totalTokens']}\"\n",
    "                if 'metrics' in metadata:\n",
    "                    output += f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\"\n",
    "\n",
    "    return output, message\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pdf_to_images(file_path):\n",
    "    saved_files = []  # List to store paths of saved files\n",
    "    \n",
    "    filename = os.path.basename(file_path)\n",
    "    base_name, ext = os.path.splitext(filename)\n",
    "    dir = os.path.dirname(file_path)\n",
    "\n",
    "    abs_path = os.path.abspath(f\"\"\"{dir}/{base_name}\"\"\")\n",
    "    os.makedirs(abs_path, exist_ok=True)\n",
    "\n",
    "    img_info = pdfinfo_from_path(file_path)\n",
    "    po = convert_from_path(file_path, 150)\n",
    "    \n",
    "    for i in range(len(po)):\n",
    "        out_file = f\"\"\"{abs_path}/page_{i}.png\"\"\"\n",
    "        po[i].save(out_file, 'PNG')\n",
    "        saved_files.append(out_file)  # Add the file path to the list\n",
    "        \n",
    "    return saved_files  # Return the list of saved file paths\n",
    "\n",
    "def save_output(source_file_path, output_ext, content):\n",
    "    filename = os.path.basename(source_file_path)\n",
    "    base_name, ext = os.path.splitext(filename)\n",
    "    dir = os.path.dirname(source_file_path)\n",
    "\n",
    "    abs_path = os.path.abspath(f\"\"\"{dir}/temp\"\"\")\n",
    "    os.makedirs(abs_path, exist_ok=True)\n",
    "\n",
    "    output_file_path = os.path.join(abs_path, f\"\"\"{base_name}.{output_ext}\"\"\")\n",
    "\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "    return output_file_path\n",
    "\n",
    "def parse_response(text):\n",
    "    \n",
    "    # Initialize variables to store contents\n",
    "    markdown_content = \"\"\n",
    "    metadata_content = \"\"\n",
    "    \n",
    "    # Find markdown content\n",
    "    markdown_start = text.find(\"<markdown>\")\n",
    "    markdown_end = text.find(\"</markdown>\")\n",
    "    if markdown_start != -1 and markdown_end != -1:\n",
    "        markdown_content = text[markdown_start + len(\"<markdown>\"):markdown_end].strip()\n",
    "    \n",
    "    # Find metadata content\n",
    "    metadata_start = text.find(\"<metadata>\")\n",
    "    metadata_end = text.find(\"</metadata>\")\n",
    "    if metadata_start != -1 and metadata_end != -1:\n",
    "        metadata_content = text[metadata_start + len(\"<metadata>\"):metadata_end].strip()\n",
    "    \n",
    "    return markdown_content, metadata_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preperation\n",
    "---\n",
    "This step handles the acquisition and initial processing of scientific documents from arXiv. It downloads sample documents and converts PDFs into individual PNG images per page, making them suitable for processing by Claude's multi-modal capabilities. This conversion is essential because Claude works better with image formats when analyzing visual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_file = 'https://arxiv.org/pdf/2003.10304'\n",
    "\n",
    "response = requests.get(sample_file)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    #get the filename from the url\n",
    "    file_type = get_file_type(response.content)\n",
    "    filename = os.path.basename(sample_file)\n",
    "    file_path = f\"\"\"./samples/{filename}.{file_type}\"\"\"\n",
    "    # Write the content to a local file\n",
    "    abs_path = os.path.abspath(os.path.dirname(file_path))\n",
    "    os.makedirs(abs_path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    sample_file_pages = pdf_to_images(file_path)\n",
    "\n",
    "sample_file_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formula Extraction\n",
    "---\n",
    "This section demonstrates how to leverage Claude's ability to recognize and extract mathematical formulas from document images. It converts formulas into LaTeX format and provides plain language descriptions, making complex mathematical content more accessible and machine-readable. This capability is particularly valuable for scientific document processing where accurate formula representation is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prompt = \"\"\"\n",
    "Evaluate this page line by line. \n",
    "For each line, if it is a formula, convert this math expression to latex format. \n",
    "Next describe the formula in plain language Be sure to enclose Latex formulas in double dollar sign for example: $$ <math expression> $$ Use markdown syntax to format your output\n",
    "\"\"\"\n",
    "\n",
    "file = \"./samples/2003.10304/page_2.png\"\n",
    "\n",
    "display(Image(filename=file, width=600))\n",
    "output, result = stream_conversation(message=sample_prompt, file_paths=[file])\n",
    "response_text = result[\"content\"]\n",
    "display(Markdown(response_text))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chart and Graph Analysis\n",
    "---\n",
    "Shows how Claude can interpret visual data from charts and graphs within scientific documents. The model provides detailed analysis of graphical elements, extracting trends, data points, and relationships. This feature is crucial for maintaining the complete semantic meaning of research papers where visual data representation is common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prompt = f\"\"\"\n",
    "You are a data scientist expert who has perfect vision and pay a lot of attention to details. \n",
    "interpret the graph on this page\n",
    "provide the answer in markdown format \"\"\"\n",
    "\n",
    "\n",
    "file = \"./samples/2003.10304/page_5.png\"\n",
    "\n",
    "display(Image(filename=file, width=600))\n",
    "output, result = stream_conversation(message=sample_prompt, file_paths=[file])\n",
    "response_text = result[\"content\"]\n",
    "display(Markdown(response_text))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Metadata Generation\n",
    "---\n",
    "Implements automated metadata extraction from scientific documents. The system generates structured metadata including title, authors, institutions, topics, and other relevant information. This metadata is essential for organizing and making documents searchable within a knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prompt = f\"\"\"\n",
    "Generate a metadata json object for this research paper. \n",
    "\n",
    "{{\n",
    "\"title\": \"\",\n",
    "\"authors\":  [],\n",
    "\"institutions\": [],\n",
    "\"topics\": [],\n",
    "\"funding-sources\": [],\n",
    "\"algorithms\":[],\n",
    "\"data_sets\":[]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "file = './samples/2003.10304/page_0.png'\n",
    "\n",
    "output, result = stream_conversation(message=sample_prompt, file_paths=[file])\n",
    "response_text = result[\"content\"]\n",
    "print(response_text)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Comprehensive Document Processing\n",
    "---\n",
    "This section combines all previous capabilities into a single workflow. It processes each page of a document to extract text, formulas, charts, and metadata in a structured format. The unified approach ensures consistent processing across all document elements while maintaining their relationships and context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prompt = \"\"\"\n",
    "Extract the content from an image page and output in Markdown syntax. Enclose the content in the <markdown></markdown> tag and do not use code blocks. If the image is empty then output a <markdown></markdown> without anything in it.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. Examine the provided page carefully.\n",
    "\n",
    "2. Identify all elements present in the page, including headers, body text, footnotes, tables, images, captions, and page numbers, etc.\n",
    "\n",
    "3. Use markdown syntax to format your output:\n",
    "    - Headings: # for main, ## for sections, ### for subsections, etc.\n",
    "    - Lists: * or - for bulleted, 1. 2. 3. for numbered\n",
    "    - Do not repeat yourself\n",
    "\n",
    "4. If the element is an image (not table)\n",
    "    - If the information in the image can be represented by a table, generate the table containing the information of the image\n",
    "    - If the image is a graph or chart, interpret the information in the graph or chart\n",
    "    - Otherwise provide a detailed description about the information in image\n",
    "    - Classify the element as one of: Chart, Diagram, Logo, Icon, Natural Image, Screenshot, Other. Enclose the class in <figure_type></figure_type>\n",
    "    - Enclose <figure_type></figure_type>, the table or description, and the figure title or caption (if available), in <figure></figure> tags\n",
    "    - Do not transcribe text in the image after providing the table or description\n",
    "\n",
    "5. If the element is a table\n",
    "    - Create a markdown table, ensuring every row has the same number of columns\n",
    "    - Maintain cell alignment as closely as possible\n",
    "    - Do not split a table into multiple tables\n",
    "    - If a merged cell spans multiple rows or columns, place the text in the top-left cell and output ' ' for other\n",
    "    - Use | for column separators, |-|-| for header row separators\n",
    "    - If a cell has multiple items, list them in separate rows\n",
    "    - If the table contains sub-headers, separate the sub-headers from the headers in another row\n",
    "\n",
    "6. If the element is a paragraph\n",
    "    - Transcribe each text element precisely as it appears\n",
    "\n",
    "7. If it is a formula\n",
    "    - Convert this math expression to latex format\n",
    "\n",
    "7. If it is code or pseudo code\n",
    "    - Format the section as code in your output\n",
    "\n",
    "8. If the element is a header, footer, footnote, page number\n",
    "    - Transcribe each text element precisely as it appears\n",
    "\n",
    "    \n",
    "Next, Generate a metadata json object that adheres to the following schema. If the page does not contain relavant metadata information for a given key, leave the value for that key empty. Enclose the metadata in <metadata></metadata> tags.\n",
    "\n",
    "{{\n",
    "\"title\": \"\",\n",
    "\"authors\":  [],\n",
    "\"institutions\": [],\n",
    "\"topics\": [],\n",
    "\"funding-sources\": [],\n",
    "\"algorithms\":[],\n",
    "\"data_sets\":[]\n",
    "}}\n",
    "\n",
    "Output Example:\n",
    "<markdown>\n",
    "<figure>\n",
    "<figure_type>Chart</figure_type>\n",
    "Figure 3: This chart shows annual sales in millions. The year 2020 was significantly down due to the COVID-19 pandemic.\n",
    "A bar chart showing annual sales figures, with the y-axis labeled \"Sales ($Million)\" and the x-axis labeled \"Year\". The chart has bars for 2018 ($12M), 2019 ($18M), 2020 ($8M), and 2021 ($22M).\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<figure_type>Chart</figure_type>\n",
    "Figure 3: This chart shows annual sales in millions. The year 2020 was significantly down due to the COVID-19 pandemic.\n",
    "| Year | Sales ($Million) |\n",
    "|-|-|\n",
    "| 2018 | $12M |\n",
    "| 2019 | $18M |\n",
    "| 2020 | $8M |\n",
    "| 2021 | $22M |\n",
    "</figure>\n",
    "\n",
    "# Annual Report\n",
    "\n",
    "## Financial Highlights\n",
    "\n",
    "<figure>\n",
    "<figure_type>Logo</figure_type>\n",
    "The logo of Apple Inc.\n",
    "</figure>\n",
    "\n",
    "* Revenue: $40M\n",
    "* Profit: $12M\n",
    "* EPS: $1.25\n",
    "\n",
    "| | Year Ended December 31, | |\n",
    "| | 2021 | 2022 |\n",
    "|-|-|-|\n",
    "| Cash provided by (used in): | | |\n",
    "| Operating activities | $ 46,327 | $ 46,752 |\n",
    "| Investing activities | (58,154) | (37,601) |\n",
    "| Financing activities | 6,291 | 9,718 |\n",
    "\n",
    "</markdown>\n",
    "<metadata>\n",
    "{{\n",
    "\"algorithms\":[\"fast fourier transform\", \"linear regression\"],\n",
    "\"data_sets\":[\"ImageNet\", \"MNIST dataset\"],\n",
    "}}\n",
    "</metadata>\n",
    "\"\"\"\n",
    "\n",
    "markdown_file_paths = []\n",
    "metadata_file_paths = []\n",
    "\n",
    "for file in sample_file_pages:\n",
    "    print(f\"processing {file}\")\n",
    "    output, result = stream_conversation(message=sample_prompt, file_paths=[file])\n",
    "    response_text = result[\"content\"]\n",
    "    markdown, metadata = parse_response(response_text)\n",
    "    \n",
    "    md_file_path = save_output(file, \"md\", markdown)\n",
    "    metadata_file_path = save_output(file, \"metadata.json\", metadata)\n",
    "    \n",
    "    markdown_file_paths.append(md_file_path)\n",
    "    metadata_file_paths.append(metadata_file_path)\n",
    "\n",
    "print(\"Markdown file paths:\", markdown_file_paths)\n",
    "print(\"Metadata file paths:\", metadata_file_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Knowledge Base Integration\n",
    "---\n",
    "Demonstrates how to prepare processed content for integration with Amazon Bedrock Knowledge Base. It includes:\n",
    "- Merging markdown files and metadata\n",
    "- Converting metadata to Bedrock's required format\n",
    "- Uploading processed content to S3\n",
    "- Creating and configuring the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_markdown_files(input_files: list, output_file: str, add_newlines: bool = True) -> Path:\n",
    "    \"\"\"\n",
    "    Merge a list of markdown files into a single file.\n",
    "    \n",
    "    Args:\n",
    "        input_files (list): List of paths to the markdown files\n",
    "        output_file (str): Path to the output merged file\n",
    "        add_newlines (bool): Whether to add newlines between merged files (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        Path: The path to the saved merged file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not all(isinstance(file, Path) for file in input_files):\n",
    "            input_files = [Path(file) for file in input_files]\n",
    "        \n",
    "        if not all(file.is_file() for file in input_files):\n",
    "            raise FileNotFoundError(\"One or more files in the list do not exist.\")\n",
    "        \n",
    "        if not input_files:\n",
    "            print(\"No markdown files provided.\")\n",
    "            return None\n",
    "        \n",
    "        output_path = Path(output_file)\n",
    "        output_dir = output_path.parent\n",
    "        \n",
    "        # Create the output directory if it does not exist\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir(parents=True)\n",
    "        \n",
    "        # Create output file\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            # Process each markdown file\n",
    "            for i, md_file in enumerate(input_files):\n",
    "                \n",
    "                # Read content from each file\n",
    "                with open(md_file, 'r', encoding='utf-8') as infile:\n",
    "                    content = infile.read()\n",
    "                    \n",
    "                    # Write content to output file\n",
    "                    outfile.write(content)\n",
    "                    \n",
    "                    # Add newline between files if not the last file\n",
    "                    if add_newlines and i < len(input_files) - 1:\n",
    "                        outfile.write('\\n\\n')\n",
    "        \n",
    "        print(f\"\\nSuccessfully merged {len(input_files)} files into '{output_path}'\")\n",
    "        return output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "markdown_file = merge_markdown_files(markdown_file_paths, \"./samples/2003.10304/kb/2003.10304.md\")\n",
    "markdown_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_bedrock_metadata(file_paths: List[str], save_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert JSON files to Amazon Bedrock knowledge bases metadata format and save the result.\n",
    "    \n",
    "    Args:\n",
    "        file_paths (List[str]): List of paths to the JSON files\n",
    "        save_path (str): Path to save the resulting Bedrock metadata JSON file\n",
    "        \n",
    "    Returns:\n",
    "        str: File path of the saved result\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_string_attribute(value: str, include_embedding: bool = True) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"value\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"stringValue\": value\n",
    "            },\n",
    "            \"includeForEmbedding\": include_embedding\n",
    "        }\n",
    "    \n",
    "    def create_string_list_attribute(values: list, include_embedding: bool = True) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"value\": {\n",
    "                \"type\": \"STRING_LIST\",\n",
    "                \"stringListValue\": values\n",
    "            },\n",
    "            \"includeForEmbedding\": include_embedding\n",
    "        }\n",
    "\n",
    "    # Initialize the metadata structure\n",
    "    bedrock_metadata = {\n",
    "        \"metadataAttributes\": {}\n",
    "    }\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for file_path in file_paths:\n",
    "        if file_path.endswith('.json'):\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Convert each field to appropriate Bedrock metadata format\n",
    "                if data.get(\"title\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"title\"] = create_string_attribute(data[\"title\"])\n",
    "                \n",
    "                if data.get(\"authors\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"authors\"] = create_string_list_attribute(data[\"authors\"])\n",
    "                \n",
    "                if data.get(\"institutions\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"institutions\"] = create_string_list_attribute(data[\"institutions\"])\n",
    "                \n",
    "                if data.get(\"topics\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"topics\"] = create_string_list_attribute(data[\"topics\"])\n",
    "                \n",
    "                if data.get(\"funding-sources\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"funding_sources\"] = create_string_list_attribute(data[\"funding-sources\"])\n",
    "                \n",
    "                if data.get(\"algorithms\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"algorithms\"] = create_string_list_attribute(data[\"algorithms\"])\n",
    "                \n",
    "                if data.get(\"data_sets\"):\n",
    "                    bedrock_metadata[\"metadataAttributes\"][\"data_sets\"] = create_string_list_attribute(data[\"data_sets\"])\n",
    "                \n",
    "                # Add creation date\n",
    "                bedrock_metadata[\"metadataAttributes\"][\"created_date\"] = {\n",
    "                    \"value\": {\n",
    "                        \"type\": \"NUMBER\",\n",
    "                        \"numberValue\": int(datetime.now().strftime(\"%Y%m%d\"))\n",
    "                    },\n",
    "                    \"includeForEmbedding\": True\n",
    "                }\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Save the resulting metadata to a file\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(bedrock_metadata, f, indent=4)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "metadata_file = convert_to_bedrock_metadata(markdown_file_paths, \"./samples/2003.10304/kb/2003.10304.md.metadata.json\")\n",
    "metadata_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_base_bucket_name = os.getenv(\"BUCKET_NAME\", f\"{account_id}-bedrock-kb-{suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_base_hierarchical = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name_hierarchical}-{suffix}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_bucket_name=knowledge_base_bucket_name, \n",
    "    chunking_strategy = \"HIERARCHICAL\", \n",
    "    suffix = f'{suffix}-h'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Create a knowledge base with the files \n",
    "\n",
    "When your files have finished uploading, follow these steps \n",
    "1. Create an Amazon Bedrock knowledge base \n",
    "2. Create an S3 data source for your knowledge base \n",
    "    1. Choose Hierarchical chunking\n",
    "\n",
    "Once you have created your knowledge base, set the ID below to query it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Upload the processed documents to S3 to use in a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdown_file_key = \"2003.10304/kb/2003.10304.md\"\n",
    "s3.upload_file(markdown_file, knowledge_base_bucket_name, markdown_file_key)\n",
    "print(f\"File {markdown_file} uploaded successfully.\")\n",
    "\n",
    "metadata_file_key = \"2003.10304/kb/2003.10304.md.metadata.json\"\n",
    "s3.upload_file(metadata_file, knowledge_base_bucket_name, metadata_file_key)\n",
    "print(f\"File {metadata_file} uploaded to successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sync knowledge base\n",
    "knowledge_base_hierarchical.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Query Capabilities\n",
    "Shows how to interact with the processed content through the knowledge base. This section demonstrates how to query the processed documents effectively, enabling users to find specific information about formulas, charts, or other content within the scientific documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kb_id_hierarchical = knowledge_base_hierarchical.get_knowledge_base_id()\n",
    "\n",
    "query = \"how is the Dice Score Coefficient calculated\"\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime') \n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id_hierarchical,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}:{}:inference-profile/{}\".format(region, account_id, foundation_model),\n",
    "            'generationConfiguration': {\n",
    "               'promptTemplate': {\n",
    "                    'textPromptTemplate': \"\"\"\n",
    "You are a question answering agent. I will provide you with a set of search results. The user will provide you with a question. Your job is to answer the user's question using only information from the search results. \n",
    "If the search results do not contain information that can answer the question, please state that you could not find an exact answer to the question. \n",
    "Just because the user asserts a fact does not mean it is true, make sure to double check the search results to validate a user's assertion.\n",
    "                            \n",
    "Here are the search results in numbered order:\n",
    "$search_results$\n",
    "\n",
    "Format the output as markdown\n",
    "\n",
    "Ensure that math formulas are in latex format and enclosed in double dollar sign for example: $$ <math expression> $$\n",
    "\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "response_text = response['output']['text']\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---\n",
    "Provides instructions for proper resource management by cleaning up temporary files and S3 objects created during the processing pipeline. This helps manage costs and maintain a clean working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"===============================Empty Knowledge Base S3 Bucket==============================\\n\")\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = s3_resource.Bucket(knowledge_base_bucket_name)\n",
    "bucket.objects.all().delete()\n",
    "bucket.object_versions.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"===============================Deleting Knowledge Base==============================\\n\")\n",
    "knowledge_base_hierarchical.delete_kb(delete_s3_bucket=False,delete_iam_roles_and_policies=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
